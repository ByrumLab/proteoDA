---
title: "Tutorial: proteomics analysis using proteoDA"
output:
  html_document:
    rmarkdown::html_vignette
vignette: >
  %\VignetteEncoding{UTF-8}
  %\VignetteIndexEntry{Tutorial: proteomics analysis using proteoDA}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Installation 

If you have this vignette, you should already have `proteoDA` installed. If not, installation is simple. `proteoDA` is not yet on CRAN, but it can be installed from GitHub using the `devtools` package:

```{r, eval = F} 

install.packages("devtools")
devtools::install_github("ByrumLab/proteoDA", 
                         dependencies = TRUE, 
                         build_vignettes = TRUE)
```

Once `proteoDA` is installed, load it:

```{r}
library(proteoDA)
```

## Data Import and Requirements

`proteoDA` stores data and results in a `DAList`, a list object with a special structure and class (its an S3 class, for the R nerds). DA stands for "differential abundance", the type of analysis a `DAList` is meant for.  A `DAList` contains 7 items (which we also call slots): data, annotation, metadata, design, eBayes_fit, results, and tags. Generally, you only need to worry about the first three slots, and `proteoDA` will take care of the rest. They are:

1. **data**- A data frame or matrix containing protein intensity values for each sample.  The rows contain data from a specific protein, and columns represent individual samples. The names of the columns must match the row names of the metadata (see below).

2. **annotation**- A data frame containing annotation information for the proetins. These could be protein accession numbers, description, gene symbols, etc. There is only one required item: the annotation data must contain a column titled "uniprot_id" (no capital letters!), and the values in that column must be unique to each row (this is how `proteoDA` keeps track of the unique proteins in your experiment).

3. **metadata**- A data frame containing sample information such as sample name, group, gender, batch, etc. The row names of the metadata must match the column names of the data. 

### Data import example

Using some example data, we'll walk through how to prepare existing data for use with `proteoDA`. Our example data consists of two files: 

1. `DIA_data.csv`, a comma-separated value file containing a mix of protein intensity and annotation data, similar to data you might receive from, for example, a Scaffold DIA file.

2. `metafile.csv`, a comma-separated value file containing sample information and metadata.

These examples come bundled with the `proteoDA` package, and we can import the files and take a look at them using standard R functions:

```{r}
input_data <- read.csv(system.file("extdata/DIA_data.csv", package = "proteoDA"))
sample_metadata <- read.csv(system.file("extdata/metafile.csv", package = "proteoDA"))
```

```{r, eval = F}
head(input_data)
```

The `input_data` is a data frame with 9089 rows (each corresponding to one protein) and 21 columns. The first 4 columns give protein annotation information: a UniProt ID, some protein info from the database search, etc. The remaining 17 columns give the per-sample protein intensities.  

```{r, eval = F}
head(sample_metadata)
```

The `sample_metadata` is a dataframe with 17 rows giving information on each sample: the column name in the `input_data` which corresponds to that sample, the sample ID, the sample batch (all the same, in this case), and a "group" column describing the sample type: 3 pooled samples used for characterizing all proteins during the database search, 7 samples from normal, non-cancercous tissue, and 7 samples from cancer tissue. The goal of our experiment is to find proteins that are differentially abundance in cancer and non-cancer cells. 

For making our `DAList` object, we need to separate out the protein annotation data and protein intensity data in the `input_data` data frame. There are a number of ways to do this in `R`, but an easy way is to subset each data frame based on the indicies of the desired columns:

```{r}
intensity_data <- input_data[,5:21] # select columns 5 to 21
annotation_data <- input_data[,1:4] # select columns 1 to 4
```

When creating data frames of intensity data and annotation information for a `DAList` object, it is important to ensure that the rows are in the right order: the `DAList()` function used to create a `DAList` keeps the rows in the order provided. If you provide the intensity and annotation data in different orders, they will not match up properly. The method above does not change the row orders. 

Finally, before creating our `DAList` object, we can return to the two requirements we mention above: 

1. The annotation data should contain a column name "uniprot_id" which contains a unique entry for each row/protein. Our example data already fulfills this criteria.

2. The row names of the metadata should equal the column names of the protein intensity data. We can check this:


```{r}
rownames(sample_metadata)
```

At the moment, the row names are just numbered: `DAList()` won't be able to match up the rows in `sample_metadata` to the columns in `intensity_data`. Fortunately, the column name information is already available in the metadata, we can just assign it to the rownames of `sample_metadata`:

```{r}
rownames(sample_metadata) <- sample_metadata$data_column_name
```

Now, we're ready to make our `DAList` of the raw data. 

```{r}
raw <- DAList(data = intensity_data,
              annotation = annotation_data,
              metadata = sample_metadata)
```

You can examine the individual elements of the `DAList` using the `$` operator in R:

```{r, eval = F}
# Look at the intensity data
raw$data

# Look at the metadata
raw$metadata
```
 
## Sample and protein filtering 

Before analysis, we need to do some filtering of the raw data. First, we can filter out some unneeded samples. Our raw data contains three pooled samples, made from pooling all the samples together. STEPHANIE ADD SOME INFO ON THE RATIONALE BEHIND THIS. We do not want to analyze these pooled samples for differential abundance. 

`proteoDA` has a function, `filter_samples()` that can be used to remove samples from a `DAList` object. All functions in `proteoDA` have reference pages, lets take a look at the reference for `filter_samples()`:

```{r, eval = F}
?filter_samples
```

This function takes two arguments: an input `DAList` and a condition: a logical expression which describes which samples should be kept. In our case, we want to remove the pool samples, and keep all non-pool samples. So, let's keep all samples where the "group" column in the sample metadata does not equal "Pool":

```{r, message = F}
filtered_samples <- filter_samples(raw, group != "Pool")
```

Next, we may want to filter out proteins with a large amount of missing data. `proteoDA` provides two functions to do this: `filter_proteins_by_group()` and `filter_proteins_by_proportion()`. With `filter_proteins_by_group()`, the user specifies the minimum number of samples and groups for which a protein must have non-missing data: e.g., a protein must be present in at least 4 samples in at least 3 groups to be kept. `filter_proteins_by_proportion()` is similar, but the user specifies a minimum proportion, instead of a minimum number: this is useful for cases when sample sizes are unequal across groups. 

Here, it is important to note that these filtering functions only filter on missing values (`r NA`), not zero values. The distinction between missing values and zeroes is important: a missing value says we do not know whether a protein was present or not, while a zero says that we know a protein definitely was not present. `proteoDA` has two functions to help you manage missing values in the way that is appropriate for your data: `zero_to_missing()` will convert 0 values to missing data, while `missing_to_zero()` will convert missing values (usually `r NA`, but you can specify other values depending on how your data are encoded) to zero. 

In our example data, many proteins have zero intensity. Generally in mass spectrometry, this is because the protein was below the detection limit of the instrument: the protein may have been present at low quantities, and we can't say for sure that the protein was not present. So, we'll convert these to missing values, and then filter out proteins with too much missing data. A good rule of thumb is to require non-missing data in ~2/3 of the replicates. For our example data, with 7 replicates per group, we'll require non-missing data for at least 4 samples:

```{r, message=FALSE}
# Convert missing values
filtered_samples <- zero_to_missing(filtered_samples)
filtered_proteins <- filter_proteins_by_group(filtered_samples,
                                              min_reps = 4,
                                              min_groups = 2,
                                              grouping_column = "group")
```

The printed message from `proteoDA` tells us that 203 proteins were removed. 

Here it is useful to note that most `proteoDA` functions take a `DAList` as input and return a `DAList` as output. This makes it easy to pipe multiple commands together into data processing pipelines. Below, we can take our raw data, remove the pool samples, convert missing values, and filter out missing proteins all in one pipeline (filtering by proportion this time, just as an example):

```{r, message = F}
filtered <- raw |>
  filter_samples(group != "Pool") |>
  zero_to_missing() |>
  filter_proteins_by_proportion(min_prop = 0.66,
                                grouping_column = "group")
```

By default, the output of the function on the left-hand side of the pipe operator, `|>`, is passed as input to the first argument of the function on the right hand side of the pipe (see the pipe operator documentation at ```?|>``` for more information). For functions in `proteoDA`, the first argument is always the input `DAList`, which makes piping commands together easy. 

## Normalization

After filtering, the raw intensity data should be normalized, so that technical variability between samples doesn't affect the inference of differential abundance. Normalization is a complex topic, and there are a wide variety of possible normalization methods. `proteoDA` includes 8 popular normalization methods and a tool to help you choose the best normalization method: `write_norm_report()`.

The `write_norm_report()` functions applies all 8 normalization methods to a dataset and outputs a PDF report containing plots of different normalization metrics. Specifically, it evaluates the pooled coefficient of variance (PCV) within sample groups, the pooled median absolute deviation (PMAD) within sample groups, the pooled estimate of variance (PEV) within sample groups, the pairwise correlation of sample intensities (COR) within sample groups, and the pairwise ratios of average log2-transformed intensities between groups. 


```{r, eval = F,message = F}
# This will save in your current workign directory by default, but
# you can use the output_dir argument to specify a different output. 
write_norm_report(filtered,
                  grouping_column = "group")
```

The first page of the PDF output should look like this:

```{r out.width = '70%', echo = FALSE, fig.align='center'}
knitr::include_graphics("images/proteiNorm.png")
```

In general, you want to pick a normalization method that has low levels of within-group variability (PCV, PMAD, and PEV) and high levels of within-group correlation (COR), with a log2 density ratio that is roughly symmetric around 0 (though, when there are only two groups being compared, as in this case, the log2 ratio plots are OK if they aren't symmetric). The second page of the normalization report (not shown) gives MA plots of average expression against the average log2 ratio between groups: a good normalization method should have a relatively flat trend (orange line). 

It is important to note that, although we need to include a grouping variable to calculate within-group statistics for *evaluating* normalization methods, the actual *calculation* of these normalizations is performed done across all samples without regard to grouping (i.e., `proteoDA` performs global, not local, normalization). Thus, providing different grouping columns when creating the normalization report might affect your evaluation of normalization methods, the underlying normalized values will be the same. 


For these example data, cyclic loess normalization ("cycloess" in the report) looks like a good choice, though all the normalization methods besides simple log2 transformation perform similarly (which is generally a good sign). Now that we've chosen that method, we can normalize our data (this will overwrite the raw data with normalized data, so it's a good idea to save this as a new `DAList` object):

```{r}
normalized <- normalize_data(filtered, 
                             norm_method = "cycloess")
```

For more information on normalization, check out [this paper](https://pubs.acs.org/doi/10.1021/pr401264n) on normalization, or [proteiNorm](https://github.com/ByrumLab/proteiNorm), an interactive normalization evaluation tool on which `proteoDA` is based. 


EDITED TO HERE

## Quality Control Report

Once the normalization method has been chosen, QC plots are generated using the selected normalized data. The QC report generates violin plots, PCA, clustered dendrograms, correlation heatmap of each sample, and a plot of proteins with missing values. 

Missing values in mass spectrometry do not mean the protein is not present in the sample but rather the protein was not detected. This might be due to the dynamic range limitations. 

```r
write_qc_report(norm,
                color_column = "group",
                label_column = NULL,        # defaults to the metafile rownames
                output_dir = "01_QC_report",
                filename = "QC_report.pdf",
                overwrite = T,
                top_proteins = 500,         # number of most variable proteins for clustering
                standardize = TRUE,
                pca_axes = c(1,2),          # first 2 PCs
                dist_metric = "euclidean",  # stats::dist for options
                clust_method = "complete",  # stats::hclust for options
                show_all_proteins = F)  # only those with missing data

```

Note that you might choose to remove outlier samples here, in which case you could go back, filter it out, and then rerun the rest of the pipeline up to here. 



## Prepare limma model design and sample group comparisons

The limma design formula must be added to the DAList() in order to run the statistical analysis. A design matrix is a model matrix of explanatory variables of a set of objects. Each row represents individual samples and the columns represent the sample groups and factors (such as batch). 

The design formula is a string for the design matrix which can include intercept ("~group"), no intercept ("~0 + group"), additive ("~group + batch"), or interaction ("~group*treatment) models. 

If the no intercept model is selected, then the add_contrasts() function allows the user to provide the sample comparisons as a file or a vector. This option allows for all pair-wise comparisons. 

If the intercept model is selected, then the sample groups are compared against the reference. 

An excellent guide for design matrices is in the following reference.  
<b>Reference:</b> Law CW, Zeglinski K, Dong X et al. A guide to creating design matrices for gene expression experiments [version 1; peer review: 2 approved]. F1000Research 2020, 9:1444 (https://doi.org/10.12688/f1000research.27893.1)

```r
norm <- add_design(norm,
                   design_formula = "~ 0 + group")


norm <- add_contrasts(norm,
                      contrasts_file = "vignette/contrasts.csv")

```

## Fit the limma differential abundance model 

Fits the limma differential abundance model to the intensity data, following the specified
design and (optional) contrast matrices. 
When a random factor is included, uses limma::duplicateCorrelation to estimate the
intra-block correlation within groups. 

Uses limma::lmFit to fit the initial model, optionally re-parameterizes the results in
terms of contrasts with limma::contrasts.fit, and then recomputes moderated statistics
following limma's empirical Bayes model with limma::eBayes.

```r
fit <- fit_limma_model(norm)

# Extract results ---------------------------------------------------------
results <- extract_DA_results(fit,
                              pval_thresh = 0.055,
                              lfc_thresh = 1,
                              adj_method = "BH",
                              extract_intercept = F)

# Write results -----------------------------------------------------------
write_limma_tables(results,
                   output_dir = "02_DA_results",
                   overwrite = T,
                   contrasts_subdir = NULL,
                   summary_csv=NULL,
                   combined_file_csv = NULL,
                   spreadsheet_xlsx = NULL,
                   add_filter = T)

write_limma_plots(results,
                  grouping_column = "group",
                  table_columns = c("uniprot_id","Description"),
                  title_column = "uniprot_id",
                  output_dir = "02_DA_results",
                  tmp_subdir = "tmp",
                  height = 1000,
                  width = 1000)
```
